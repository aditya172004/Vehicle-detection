{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "b49bba4b-f395-4373-ad9f-782e67ca0140",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vehicle counter started. Press 'q' to quit.\n",
      "\n",
      "--- Final Cumulative Counts ---\n",
      "Total Unique Vehicles Detected: 57\n",
      "- Car: 48\n",
      "- Truck: 8\n",
      "- Bus: 1\n"
     ]
    }
   ],
   "source": [
    "# Enhanced Real-time Vehicle Counter with Detection and Frequency Improvements\n",
    "# Requirements: pip install ultralytics opencv-python\n",
    "#-----------------------------------------------------------------botsort ALGO---------------------------\n",
    "#  -------------------------BOTH INCOMING AND OUTGOING VEHICLES--------------------------------\n",
    "import cv2\n",
    "from ultralytics import YOLO\n",
    "from collections import defaultdict\n",
    "import time\n",
    "import numpy as np\n",
    "\n",
    "class VehicleCounter:\n",
    "    def __init__(self, model_path='yolov10s.pt', conf_threshold=0.3, device='cpu', use_clahe=True):\n",
    "        \"\"\"\n",
    "        Initializes the VehicleCounter.\n",
    "\n",
    "        Args:\n",
    "            model_path (str): Path to the YOLO model file (e.g., 'yolov10s.pt').\n",
    "            conf_threshold (float): Confidence threshold for object detection.\n",
    "            device (str): Device to run the model on ('cpu' or '0' for GPU).\n",
    "            use_clahe (bool): Whether to apply CLAHE pre-processing for better contrast.\n",
    "        \"\"\"\n",
    "        self.model = YOLO(model_path)\n",
    "        self.conf_threshold = conf_threshold\n",
    "        self.device = device\n",
    "        self.use_clahe = use_clahe\n",
    "        \n",
    "        # Initialize CLAHE pre-processor if enabled\n",
    "        if self.use_clahe:\n",
    "            self.clahe = cv2.createCLAHE(clipLimit=2.0, tileGridSize=(8, 8))\n",
    "\n",
    "        self.vehicle_classes = {\n",
    "            2: 'car', 3: 'motorcycle', 5: 'bus', 7: 'truck'\n",
    "        }\n",
    "\n",
    "        # Tracking and counting attributes\n",
    "        self.track_history = defaultdict(list)\n",
    "        self.seen_ids = set()\n",
    "        self.vehicle_counts = defaultdict(int)\n",
    "        self.current_vehicles_in_frame = {}\n",
    "        \n",
    "        # Performance metrics\n",
    "        self.start_time = time.time()\n",
    "        self.frame_count = 0\n",
    "\n",
    "    def preprocess_frame(self, frame):\n",
    "        \"\"\"Applies pre-processing steps to the frame.\"\"\"\n",
    "        if not self.use_clahe:\n",
    "            return frame\n",
    "        \n",
    "        # Convert frame to LAB color space to apply CLAHE on the L-channel (Lightness)\n",
    "        lab = cv2.cvtColor(frame, cv2.COLOR_BGR2LAB)\n",
    "        l, a, b = cv2.split(lab)\n",
    "        l_clahe = self.clahe.apply(l)\n",
    "        lab_clahe = cv2.merge((l_clahe, a, b))\n",
    "        frame_clahe = cv2.cvtColor(lab_clahe, cv2.COLOR_LAB2BGR)\n",
    "        return frame_clahe\n",
    "\n",
    "    def process_frame(self, frame):\n",
    "        \"\"\"\n",
    "        Processes a single frame for vehicle detection, tracking, and counting.\n",
    "        \"\"\"\n",
    "        self.frame_count += 1\n",
    "        \n",
    "        # 1. Pre-process the frame for better detection\n",
    "        preprocessed_frame = self.preprocess_frame(frame)\n",
    "        \n",
    "        # 2. Run tracking on the pre-processed frame\n",
    "        results = self.model.track(\n",
    "        preprocessed_frame,\n",
    "        classes=list(self.vehicle_classes.keys()),\n",
    "        conf=self.conf_threshold,\n",
    "        device=self.device,\n",
    "        persist=True,\n",
    "        tracker=\"botsort.yaml\",  # <-- BoT-SORT used\n",
    "        verbose=False\n",
    "    )\n",
    "\n",
    "\n",
    "        \n",
    "        self.current_vehicles_in_frame.clear()\n",
    "\n",
    "        if results[0].boxes.id is not None:\n",
    "            boxes = results[0].boxes.xyxy.cpu().numpy()\n",
    "            track_ids = results[0].boxes.id.cpu().numpy().astype(int)\n",
    "            classes = results[0].boxes.cls.cpu().numpy().astype(int)\n",
    "            \n",
    "            for box, track_id, cls in zip(boxes, track_ids, classes):\n",
    "                class_name = self.vehicle_classes.get(cls, 'unknown')\n",
    "                self.current_vehicles_in_frame[track_id] = class_name\n",
    "\n",
    "                if track_id not in self.seen_ids:\n",
    "                    self.seen_ids.add(track_id)\n",
    "                    self.vehicle_counts[class_name] += 1\n",
    "                \n",
    "                cx, cy = int((box[0] + box[2]) / 2), int((box[1] + box[3]) / 2)\n",
    "                self.track_history[track_id].append((cx, cy))\n",
    "                if len(self.track_history[track_id]) > 30:\n",
    "                    self.track_history[track_id].pop(0)\n",
    "\n",
    "        # 3. Draw annotations on the ORIGINAL frame, not the pre-processed one\n",
    "        annotated_frame = self.draw_annotations(frame, results)\n",
    "        return annotated_frame\n",
    "\n",
    "    def draw_annotations(self, frame, results):\n",
    "        \"\"\"Draws bounding boxes, tracking IDs, trajectories, and statistics.\"\"\"\n",
    "        # ... (This function remains the same as the previous version)\n",
    "        if results[0].boxes.id is not None:\n",
    "            boxes = results[0].boxes.xyxy.cpu().numpy()\n",
    "            track_ids = results[0].boxes.id.cpu().numpy().astype(int)\n",
    "            classes = results[0].boxes.cls.cpu().numpy().astype(int)\n",
    "            \n",
    "            for box, track_id, cls in zip(boxes, track_ids, classes):\n",
    "                x1, y1, x2, y2 = map(int, box)\n",
    "                class_name = self.vehicle_classes.get(cls, 'unknown')\n",
    "                color = (0, 255, 0)\n",
    "\n",
    "                cv2.rectangle(frame, (x1, y1), (x2, y2), color, 2)\n",
    "                label = f'ID:{track_id} {class_name}'\n",
    "                \n",
    "                label_size, _ = cv2.getTextSize(label, cv2.FONT_HERSHEY_SIMPLEX, 0.5, 2)\n",
    "                cv2.rectangle(frame, (x1, y1 - label_size[1] - 5), (x1 + label_size[0], y1), color, -1)\n",
    "                cv2.putText(frame, label, (x1, y1 - 5), cv2.FONT_HERSHEY_SIMPLEX, 0.5, (0, 0, 0), 2)\n",
    "\n",
    "                points = self.track_history.get(track_id, [])\n",
    "                if len(points) > 1:\n",
    "                    cv2.polylines(frame, [np.array(points, dtype=np.int32)], isClosed=False, color=color, thickness=2)\n",
    "\n",
    "        self.draw_statistics(frame)\n",
    "        return frame\n",
    "\n",
    "    def draw_statistics(self, frame):\n",
    "        \"\"\"Draws the statistics panel.\"\"\"\n",
    "        # ... (This function remains the same as the previous version)\n",
    "        panel_x, panel_y, panel_w, panel_h = 10, 10, 280, 150\n",
    "        overlay = frame.copy()\n",
    "        cv2.rectangle(overlay, (panel_x, panel_y), (panel_x + panel_w, panel_y + panel_h), (0, 0, 0), -1)\n",
    "        cv2.addWeighted(overlay, 0.6, frame, 0.4, 0, frame)\n",
    "\n",
    "        y = panel_y + 25\n",
    "        lh = 20\n",
    "        \n",
    "        total_unique_count = len(self.seen_ids)\n",
    "        current_frame_count = len(self.current_vehicles_in_frame)\n",
    "        \n",
    "        cv2.putText(frame, f\"Total Unique Vehicles: {total_unique_count}\", (panel_x + 10, y), cv2.FONT_HERSHEY_SIMPLEX, 0.6, (0, 255, 255), 2)\n",
    "        y += lh + 5\n",
    "        cv2.putText(frame, f\"Current in Frame: {current_frame_count}\", (panel_x + 10, y), cv2.FONT_HERSHEY_SIMPLEX, 0.6, (0, 255, 255), 2)\n",
    "        y += lh + 10\n",
    "\n",
    "        for vehicle_type, count in self.vehicle_counts.items():\n",
    "            cv2.putText(frame, f\"- {vehicle_type.capitalize()}: {count}\", (panel_x + 10, y), cv2.FONT_HERSHEY_SIMPLEX, 0.5, (255, 255, 255), 1)\n",
    "            y += lh\n",
    "\n",
    "        elapsed_time = time.time() - self.start_time\n",
    "        fps = self.frame_count / elapsed_time if elapsed_time > 0 else 0\n",
    "        cv2.putText(frame, f\"FPS: {fps:.2f}\", (panel_x + 10, y + 5), cv2.FONT_HERSHEY_SIMPLEX, 0.6, (0, 255, 0), 2)\n",
    "\n",
    "\n",
    "    def run(self, source_path):\n",
    "        \"\"\"Runs the vehicle counting process on a video file or camera source.\"\"\"\n",
    "        # ... (This function remains the same as the previous version)\n",
    "        cap = cv2.VideoCapture(source_path)\n",
    "        if not cap.isOpened():\n",
    "            print(f\"Error: Could not open video source: {source_path}\")\n",
    "            return\n",
    "\n",
    "        display_width, display_height = 1280, 720\n",
    "        print(\"Vehicle counter started. Press 'q' to quit.\")\n",
    "\n",
    "        while True:\n",
    "            ret, frame = cap.read()\n",
    "            if not ret:\n",
    "                print(\"End of video stream.\")\n",
    "                break\n",
    "\n",
    "            frame = cv2.resize(frame, (display_width, display_height))\n",
    "            processed_frame = self.process_frame(frame)\n",
    "            cv2.imshow(\"Vehicle Counter\", processed_frame)\n",
    "\n",
    "            if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "                break\n",
    "\n",
    "        cap.release()\n",
    "        cv2.destroyAllWindows()\n",
    "        self.print_final_counts()\n",
    "\n",
    "    def print_final_counts(self):\n",
    "        \"\"\"Prints the final cumulative vehicle counts to the console.\"\"\"\n",
    "        # ... (This function remains the same as the previous version)\n",
    "        print(\"\\n--- Final Cumulative Counts ---\")\n",
    "        total_count = len(self.seen_ids)\n",
    "        print(f\"Total Unique Vehicles Detected: {total_count}\")\n",
    "        for vt, count in self.vehicle_counts.items():\n",
    "            print(f\"- {vt.capitalize()}: {count}\")\n",
    "\n",
    "\n",
    "def main():\n",
    "    # --- Configuration ---\n",
    "\n",
    "    # LEVEL 1: CHOOSE A MORE ACCURATE MODEL\n",
    "    # 'yolov10n.pt': Fastest, baseline accuracy.\n",
    "    # 'yolov10s.pt': Good balance of speed and accuracy.\n",
    "    # 'yolov10m.pt': High accuracy, best with GPU.\n",
    "    model = 'yolov10n.pt'\n",
    "    \n",
    "    # Use '0' for GPU for a massive FPS boost.\n",
    "    device_to_use = 'cpu' \n",
    "    \n",
    "    # LEVEL 2: ENABLE/DISABLE IMAGE PRE-PROCESSING\n",
    "    # Set to True to improve detection in difficult lighting. May slightly decrease FPS.\n",
    "    use_image_enhancement = True\n",
    "    \n",
    "    video_source = \"adi.mp4\" \n",
    "\n",
    "    # ADVANCED: For TensorRT, you would first export the model:\n",
    "    # from ultralytics import YOLO\n",
    "    # model = YOLO('yolov10s.pt')\n",
    "    # model.export(format='tensorrt', device='0') # Creates yolov10s.engine\n",
    "    # And then you would load 'yolov10s.engine' instead of '.pt'\n",
    "    # model_path = 'yolov10s.engine'\n",
    "\n",
    "    counter = VehicleCounter(\n",
    "        model_path=model, \n",
    "        device=device_to_use, \n",
    "        conf_threshold=0.3,\n",
    "        use_clahe=use_image_enhancement\n",
    "    )\n",
    "    counter.run(source_path=video_source)\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bdbcd917-1c58-443e-8514-88404621c5cc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vehicle counter started. Press 'q' to quit.\n",
      "\n",
      "--- Final Cumulative Counts ---\n",
      "Total Unique Vehicles Detected: 76\n",
      "- Car: 63\n",
      "- Truck: 12\n",
      "- Bus: 1\n"
     ]
    }
   ],
   "source": [
    "# Requirements: pip install ultralytics opencv-python\n",
    "# ----------------------------------------------------------------byteTrack ALGO---------------------\n",
    "#  -------------------------BOTH INCOMING AND OUTGOING VEHICLES--------------------------------\n",
    "import cv2\n",
    "from ultralytics import YOLO\n",
    "from collections import defaultdict\n",
    "import time\n",
    "import numpy as np\n",
    "\n",
    "class VehicleCounter:\n",
    "    def __init__(self, model_path='yolov10s.pt', conf_threshold=0.3, device='cpu', use_clahe=True):\n",
    "        \"\"\"\n",
    "        Initializes the VehicleCounter.\n",
    "\n",
    "        Args:\n",
    "            model_path (str): Path to the YOLO model file (e.g., 'yolov10s.pt').\n",
    "            conf_threshold (float): Confidence threshold for object detection.\n",
    "            device (str): Device to run the model on ('cpu' or '0' for GPU).\n",
    "            use_clahe (bool): Whether to apply CLAHE pre-processing for better contrast.\n",
    "        \"\"\"\n",
    "        self.model = YOLO(model_path)\n",
    "        self.conf_threshold = conf_threshold\n",
    "        self.device = device\n",
    "        self.use_clahe = use_clahe\n",
    "        \n",
    "        # Initialize CLAHE pre-processor if enabled\n",
    "        if self.use_clahe:\n",
    "            self.clahe = cv2.createCLAHE(clipLimit=2.0, tileGridSize=(8, 8))\n",
    "\n",
    "        self.vehicle_classes = {\n",
    "            2: 'car', 3: 'motorcycle', 5: 'bus', 7: 'truck'\n",
    "        }\n",
    "\n",
    "        # Tracking and counting attributes\n",
    "        self.track_history = defaultdict(list)\n",
    "        self.seen_ids = set()\n",
    "        self.vehicle_counts = defaultdict(int)\n",
    "        self.current_vehicles_in_frame = {}\n",
    "        \n",
    "        # Performance metrics\n",
    "        self.start_time = time.time()\n",
    "        self.frame_count = 0\n",
    "\n",
    "    def preprocess_frame(self, frame):\n",
    "        \"\"\"Applies pre-processing steps to the frame.\"\"\"\n",
    "        if not self.use_clahe:\n",
    "            return frame\n",
    "        \n",
    "        # Convert frame to LAB color space to apply CLAHE on the L-channel (Lightness)\n",
    "        lab = cv2.cvtColor(frame, cv2.COLOR_BGR2LAB)\n",
    "        l, a, b = cv2.split(lab)\n",
    "        l_clahe = self.clahe.apply(l)\n",
    "        lab_clahe = cv2.merge((l_clahe, a, b))\n",
    "        frame_clahe = cv2.cvtColor(lab_clahe, cv2.COLOR_LAB2BGR)\n",
    "        return frame_clahe\n",
    "\n",
    "    def process_frame(self, frame):\n",
    "        \"\"\"\n",
    "        Processes a single frame for vehicle detection, tracking, and counting.\n",
    "        \"\"\"\n",
    "        self.frame_count += 1\n",
    "        \n",
    "        # 1. Pre-process the frame for better detection\n",
    "        preprocessed_frame = self.preprocess_frame(frame)\n",
    "        \n",
    "        # 2. Run tracking on the pre-processed frame\n",
    "        results = self.model.track(\n",
    "            preprocessed_frame,\n",
    "            classes=list(self.vehicle_classes.keys()),\n",
    "            conf=self.conf_threshold,\n",
    "            device=self.device,\n",
    "            persist=True,\n",
    "            # For advanced tracker tuning, create a custom yaml file\n",
    "            # tracker=\"custom_bytetrack.yaml\", \n",
    "            tracker=\"bytetrack.yaml\",\n",
    "            verbose=False\n",
    "        )\n",
    "        \n",
    "        self.current_vehicles_in_frame.clear()\n",
    "\n",
    "        if results[0].boxes.id is not None:\n",
    "            boxes = results[0].boxes.xyxy.cpu().numpy()\n",
    "            track_ids = results[0].boxes.id.cpu().numpy().astype(int)\n",
    "            classes = results[0].boxes.cls.cpu().numpy().astype(int)\n",
    "            \n",
    "            for box, track_id, cls in zip(boxes, track_ids, classes):\n",
    "                class_name = self.vehicle_classes.get(cls, 'unknown')\n",
    "                self.current_vehicles_in_frame[track_id] = class_name\n",
    "\n",
    "                if track_id not in self.seen_ids:\n",
    "                    self.seen_ids.add(track_id)\n",
    "                    self.vehicle_counts[class_name] += 1\n",
    "                \n",
    "                cx, cy = int((box[0] + box[2]) / 2), int((box[1] + box[3]) / 2)\n",
    "                self.track_history[track_id].append((cx, cy))\n",
    "                if len(self.track_history[track_id]) > 30:\n",
    "                    self.track_history[track_id].pop(0)\n",
    "\n",
    "        # 3. Draw annotations on the ORIGINAL frame, not the pre-processed one\n",
    "        annotated_frame = self.draw_annotations(frame, results)\n",
    "        return annotated_frame\n",
    "\n",
    "    def draw_annotations(self, frame, results):\n",
    "        \"\"\"Draws bounding boxes, tracking IDs, trajectories, and statistics.\"\"\"\n",
    "        # ... (This function remains the same as the previous version)\n",
    "        if results[0].boxes.id is not None:\n",
    "            boxes = results[0].boxes.xyxy.cpu().numpy()\n",
    "            track_ids = results[0].boxes.id.cpu().numpy().astype(int)\n",
    "            classes = results[0].boxes.cls.cpu().numpy().astype(int)\n",
    "            \n",
    "            for box, track_id, cls in zip(boxes, track_ids, classes):\n",
    "                x1, y1, x2, y2 = map(int, box)\n",
    "                class_name = self.vehicle_classes.get(cls, 'unknown')\n",
    "                color = (0, 255, 0)\n",
    "\n",
    "                cv2.rectangle(frame, (x1, y1), (x2, y2), color, 2)\n",
    "                label = f'ID:{track_id} {class_name}'\n",
    "                \n",
    "                label_size, _ = cv2.getTextSize(label, cv2.FONT_HERSHEY_SIMPLEX, 0.5, 2)\n",
    "                cv2.rectangle(frame, (x1, y1 - label_size[1] - 5), (x1 + label_size[0], y1), color, -1)\n",
    "                cv2.putText(frame, label, (x1, y1 - 5), cv2.FONT_HERSHEY_SIMPLEX, 0.5, (0, 0, 0), 2)\n",
    "\n",
    "                points = self.track_history.get(track_id, [])\n",
    "                if len(points) > 1:\n",
    "                    cv2.polylines(frame, [np.array(points, dtype=np.int32)], isClosed=False, color=color, thickness=2)\n",
    "\n",
    "        self.draw_statistics(frame)\n",
    "        return frame\n",
    "\n",
    "    def draw_statistics(self, frame):\n",
    "        \"\"\"Draws the statistics panel.\"\"\"\n",
    "    \n",
    "        panel_x, panel_y, panel_w, panel_h = 10, 10, 280, 150\n",
    "        overlay = frame.copy()\n",
    "        cv2.rectangle(overlay, (panel_x, panel_y), (panel_x + panel_w, panel_y + panel_h), (0, 0, 0), -1)\n",
    "        cv2.addWeighted(overlay, 0.6, frame, 0.4, 0, frame)\n",
    "\n",
    "        y = panel_y + 25\n",
    "        lh = 20\n",
    "        \n",
    "        total_unique_count = len(self.seen_ids)\n",
    "        current_frame_count = len(self.current_vehicles_in_frame)\n",
    "        \n",
    "        cv2.putText(frame, f\"Total Unique Vehicles: {total_unique_count}\", (panel_x + 10, y), cv2.FONT_HERSHEY_SIMPLEX, 0.6, (0, 255, 255), 2)\n",
    "        y += lh + 5\n",
    "        cv2.putText(frame, f\"Current in Frame: {current_frame_count}\", (panel_x + 10, y), cv2.FONT_HERSHEY_SIMPLEX, 0.6, (0, 255, 255), 2)\n",
    "        y += lh + 10\n",
    "\n",
    "        for vehicle_type, count in self.vehicle_counts.items():\n",
    "            cv2.putText(frame, f\"- {vehicle_type.capitalize()}: {count}\", (panel_x + 10, y), cv2.FONT_HERSHEY_SIMPLEX, 0.5, (255, 255, 255), 1)\n",
    "            y += lh\n",
    "\n",
    "        elapsed_time = time.time() - self.start_time\n",
    "        fps = self.frame_count / elapsed_time if elapsed_time > 0 else 0\n",
    "        cv2.putText(frame, f\"FPS: {fps:.2f}\", (panel_x + 10, y + 5), cv2.FONT_HERSHEY_SIMPLEX, 0.6, (0, 255, 0), 2)\n",
    "\n",
    "\n",
    "    def run(self, source_path):\n",
    "        \"\"\"Runs the vehicle counting process on a video file or camera source.\"\"\"\n",
    "\n",
    "        cap = cv2.VideoCapture(source_path)\n",
    "        if not cap.isOpened():\n",
    "            print(f\"Error: Could not open video source: {source_path}\")\n",
    "            return\n",
    "\n",
    "        display_width, display_height = 1280, 720\n",
    "        print(\"Vehicle counter started. Press 'q' to quit.\")\n",
    "\n",
    "        while True:\n",
    "            ret, frame = cap.read()\n",
    "            if not ret:\n",
    "                print(\"End of video stream.\")\n",
    "                break\n",
    "\n",
    "            frame = cv2.resize(frame, (display_width, display_height))\n",
    "            processed_frame = self.process_frame(frame)\n",
    "            cv2.imshow(\"Vehicle Counter\", processed_frame)\n",
    "\n",
    "            if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "                break\n",
    "\n",
    "        cap.release()\n",
    "        cv2.destroyAllWindows()\n",
    "        self.print_final_counts()\n",
    "\n",
    "    def print_final_counts(self):\n",
    "        \"\"\"Prints the final cumulative vehicle counts to the console.\"\"\"\n",
    "        print(\"\\n--- Final Cumulative Counts ---\")\n",
    "        total_count = len(self.seen_ids)\n",
    "        print(f\"Total Unique Vehicles Detected: {total_count}\")\n",
    "        for vt, count in self.vehicle_counts.items():\n",
    "            print(f\"- {vt.capitalize()}: {count}\")\n",
    "\n",
    "\n",
    "def main():\n",
    "    # --- Configuration ---\n",
    "\n",
    "    # LEVEL 1: CHOOSE A MORE ACCURATE MODEL\n",
    "    # 'yolov10n.pt': Fastest, baseline accuracy.\n",
    "    # 'yolov10s.pt': Good balance of speed and accuracy.\n",
    "    # 'yolov10m.pt': High accuracy, best with GPU.\n",
    "    model = 'yolov10n.pt'\n",
    "    \n",
    "    # Use '0' for GPU for a massive FPS boost.\n",
    "    device_to_use = 'cpu' \n",
    "    \n",
    "    # LEVEL 2: ENABLE/DISABLE IMAGE PRE-PROCESSING\n",
    "    # Set to True to improve detection in difficult lighting. May slightly decrease FPS.\n",
    "    use_image_enhancement = True\n",
    "    \n",
    "    video_source = \"adi.mp4\" \n",
    "\n",
    "    # ADVANCED: For TensorRT, you would first export the model:\n",
    "    # from ultralytics import YOLO\n",
    "    # model = YOLO('yolov10s.pt')\n",
    "    # model.export(format='tensorrt', device='0') # Creates yolov10s.engine\n",
    "    # And then you would load 'yolov10s.engine' instead of '.pt'\n",
    "    # model_path = 'yolov10s.engine'\n",
    "\n",
    "    counter = VehicleCounter(\n",
    "        model_path=model, \n",
    "        device=device_to_use, \n",
    "        conf_threshold=0.3,\n",
    "        use_clahe=use_image_enhancement\n",
    "    )\n",
    "    counter.run(source_path=video_source)\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "fe21c82a-8f9d-4108-9b81-b6c2cebbcefa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Incoming vehicle counter started. Press 'q' to quit.\n",
      "\n",
      "--- Final Incoming Vehicle Counts ---\n",
      "Total Incoming Vehicles Detected: 7\n",
      "- Car: 7\n"
     ]
    }
   ],
   "source": [
    "# Enhanced Real-time Vehicle Counter (Incoming Vehicles Only)\n",
    "# Requirements: pip install ultralytics opencv-python\n",
    "# ----------------------------------------------------------------\n",
    "\n",
    "import cv2\n",
    "from ultralytics import YOLO\n",
    "from collections import defaultdict\n",
    "import time\n",
    "import numpy as np\n",
    "\n",
    "class VehicleCounter:\n",
    "    def __init__(self, model_path='yolov10s.pt', conf_threshold=0.3, device='cpu', use_clahe=True):\n",
    "        self.model = YOLO(model_path)\n",
    "        self.conf_threshold = conf_threshold\n",
    "        self.device = device\n",
    "        self.use_clahe = use_clahe\n",
    "        \n",
    "        if self.use_clahe:\n",
    "            self.clahe = cv2.createCLAHE(clipLimit=2.0, tileGridSize=(8, 8))\n",
    "\n",
    "        self.vehicle_classes = {\n",
    "            2: 'car', 3: 'motorcycle', 5: 'bus', 7: 'truck'\n",
    "        }\n",
    "\n",
    "        self.track_history = defaultdict(list)\n",
    "        self.counted_ids = set()\n",
    "        self.vehicle_counts = defaultdict(int)\n",
    "        self.current_vehicles_in_frame = {}\n",
    "        self.start_time = time.time()\n",
    "        self.frame_count = 0\n",
    "\n",
    "    def preprocess_frame(self, frame):\n",
    "        if not self.use_clahe:\n",
    "            return frame\n",
    "        \n",
    "        lab = cv2.cvtColor(frame, cv2.COLOR_BGR2LAB)\n",
    "        l, a, b = cv2.split(lab)\n",
    "        l_clahe = self.clahe.apply(l)\n",
    "        lab_clahe = cv2.merge((l_clahe, a, b))\n",
    "        return cv2.cvtColor(lab_clahe, cv2.COLOR_LAB2BGR)\n",
    "\n",
    "    def process_frame(self, frame):\n",
    "        self.frame_count += 1\n",
    "        preprocessed = self.preprocess_frame(frame)\n",
    "        results = self.model.track(\n",
    "            preprocessed,\n",
    "            classes=list(self.vehicle_classes.keys()),\n",
    "            conf=self.conf_threshold,\n",
    "            device=self.device,\n",
    "            persist=True,\n",
    "            tracker=\"bytetrack.yaml\",\n",
    "            verbose=False\n",
    "        )\n",
    "\n",
    "        self.current_vehicles_in_frame.clear()\n",
    "\n",
    "        if results[0].boxes.id is not None:\n",
    "            boxes = results[0].boxes.xyxy.cpu().numpy()\n",
    "            ids = results[0].boxes.id.cpu().numpy().astype(int)\n",
    "            classes = results[0].boxes.cls.cpu().numpy().astype(int)\n",
    "\n",
    "            for box, track_id, cls in zip(boxes, ids, classes):\n",
    "                class_name = self.vehicle_classes.get(cls, 'unknown')\n",
    "                self.current_vehicles_in_frame[track_id] = class_name\n",
    "\n",
    "                cx = int((box[0] + box[2]) / 2)\n",
    "                cy = int((box[1] + box[3]) / 2)\n",
    "                self.track_history[track_id].append((cx, cy))\n",
    "\n",
    "                # Count incoming only (e.g., moving downward)\n",
    "                if len(self.track_history[track_id]) > 10:\n",
    "                    y_positions = [pt[1] for pt in self.track_history[track_id][-10:]]\n",
    "                    dy = y_positions[-1] - y_positions[0]  # Positive if moving down\n",
    "\n",
    "                    if dy > 15 and track_id not in self.counted_ids:\n",
    "                        self.counted_ids.add(track_id)\n",
    "                        self.vehicle_counts[class_name] += 1\n",
    "\n",
    "                if len(self.track_history[track_id]) > 30:\n",
    "                    self.track_history[track_id].pop(0)\n",
    "\n",
    "        return self.draw_annotations(frame, results)\n",
    "\n",
    "    def draw_annotations(self, frame, results):\n",
    "        if results[0].boxes.id is not None:\n",
    "            boxes = results[0].boxes.xyxy.cpu().numpy()\n",
    "            ids = results[0].boxes.id.cpu().numpy().astype(int)\n",
    "            classes = results[0].boxes.cls.cpu().numpy().astype(int)\n",
    "\n",
    "            for box, track_id, cls in zip(boxes, ids, classes):\n",
    "                x1, y1, x2, y2 = map(int, box)\n",
    "                class_name = self.vehicle_classes.get(cls, 'unknown')\n",
    "                color = (0, 255, 0)\n",
    "                label = f'ID:{track_id} {class_name}'\n",
    "\n",
    "                cv2.rectangle(frame, (x1, y1), (x2, y2), color, 2)\n",
    "                label_size, _ = cv2.getTextSize(label, cv2.FONT_HERSHEY_SIMPLEX, 0.5, 2)\n",
    "                cv2.rectangle(frame, (x1, y1 - label_size[1] - 5), (x1 + label_size[0], y1), color, -1)\n",
    "                cv2.putText(frame, label, (x1, y1 - 5), cv2.FONT_HERSHEY_SIMPLEX, 0.5, (0, 0, 0), 2)\n",
    "\n",
    "                points = self.track_history.get(track_id, [])\n",
    "                if len(points) > 1:\n",
    "                    cv2.polylines(frame, [np.array(points, dtype=np.int32)], False, color, 2)\n",
    "\n",
    "        self.draw_statistics(frame)\n",
    "        return frame\n",
    "\n",
    "    def draw_statistics(self, frame):\n",
    "        panel_x, panel_y, panel_w, panel_h = 10, 10, 280, 150\n",
    "        overlay = frame.copy()\n",
    "        cv2.rectangle(overlay, (panel_x, panel_y), (panel_x + panel_w, panel_y + panel_h), (0, 0, 0), -1)\n",
    "        cv2.addWeighted(overlay, 0.6, frame, 0.4, 0, frame)\n",
    "\n",
    "        y = panel_y + 25\n",
    "        lh = 20\n",
    "\n",
    "        total_unique_count = len(self.counted_ids)\n",
    "        current_frame_count = len(self.current_vehicles_in_frame)\n",
    "\n",
    "        cv2.putText(frame, f\"Incoming Vehicles Counted: {total_unique_count}\", (panel_x + 10, y), cv2.FONT_HERSHEY_SIMPLEX, 0.6, (0, 255, 255), 2)\n",
    "        y += lh + 5\n",
    "        cv2.putText(frame, f\"Current in Frame: {current_frame_count}\", (panel_x + 10, y), cv2.FONT_HERSHEY_SIMPLEX, 0.6, (0, 255, 255), 2)\n",
    "        y += lh + 10\n",
    "\n",
    "        for vt, count in self.vehicle_counts.items():\n",
    "            cv2.putText(frame, f\"- {vt.capitalize()}: {count}\", (panel_x + 10, y), cv2.FONT_HERSHEY_SIMPLEX, 0.5, (255, 255, 255), 1)\n",
    "            y += lh\n",
    "\n",
    "        elapsed_time = time.time() - self.start_time\n",
    "        fps = self.frame_count / elapsed_time if elapsed_time > 0 else 0\n",
    "        cv2.putText(frame, f\"FPS: {fps:.2f}\", (panel_x + 10, y + 5), cv2.FONT_HERSHEY_SIMPLEX, 0.6, (0, 255, 0), 2)\n",
    "\n",
    "    def run(self, source_path):\n",
    "        cap = cv2.VideoCapture(source_path)\n",
    "        if not cap.isOpened():\n",
    "            print(f\"Error: Could not open video source: {source_path}\")\n",
    "            return\n",
    "\n",
    "        display_width, display_height = 1280, 720\n",
    "        print(\"Incoming vehicle counter started. Press 'q' to quit.\")\n",
    "\n",
    "        while True:\n",
    "            ret, frame = cap.read()\n",
    "            if not ret:\n",
    "                print(\"End of video stream.\")\n",
    "                break\n",
    "\n",
    "            frame = cv2.resize(frame, (display_width, display_height))\n",
    "            processed_frame = self.process_frame(frame)\n",
    "            cv2.imshow(\"Incoming Vehicle Counter\", processed_frame)\n",
    "\n",
    "            if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "                break\n",
    "\n",
    "        cap.release()\n",
    "        cv2.destroyAllWindows()\n",
    "        self.print_final_counts()\n",
    "\n",
    "    def print_final_counts(self):\n",
    "        print(\"\\n--- Final Incoming Vehicle Counts ---\")\n",
    "        total = len(self.counted_ids)\n",
    "        print(f\"Total Incoming Vehicles Detected: {total}\")\n",
    "        for vt, count in self.vehicle_counts.items():\n",
    "            print(f\"- {vt.capitalize()}: {count}\")\n",
    "\n",
    "\n",
    "def main():\n",
    "    model = 'yolov10n.pt'  # Change to 'yolov10s.pt' or 'yolov10m.pt' for better accuracy if needed\n",
    "    device_to_use = 'cpu'  # Use '0' for GPU\n",
    "    use_image_enhancement = True\n",
    "    video_source = \"adi.mp4\"\n",
    "\n",
    "    counter = VehicleCounter(\n",
    "        model_path=model, \n",
    "        device=device_to_use, \n",
    "        conf_threshold=0.3,\n",
    "        use_clahe=use_image_enhancement\n",
    "    )\n",
    "    counter.run(source_path=video_source)\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "9ec245bc-e526-418b-8f67-14f6dfcbbf89",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Real-time vehicle counter started. Press 'q' to quit.\n",
      "\n",
      "Real-time counting session ended.\n"
     ]
    }
   ],
   "source": [
    "# Real-time Vehicle Counter (Incoming - Strict Heuristic, Outgoing - Reference Line)\n",
    "# Requirements: pip install ultralytics opencv-python\n",
    "# ----------------------------------------------------------------byteTrack ALGO---------------------\n",
    "\n",
    "import cv2\n",
    "from ultralytics import YOLO\n",
    "from collections import defaultdict\n",
    "import time\n",
    "import numpy as np\n",
    "\n",
    "class VehicleCounter:\n",
    "    def __init__(self, model_path='yolov10s.pt', conf_threshold=0.3, device='cpu', use_clahe=True):\n",
    "        \"\"\"\n",
    "        Initializes the VehicleCounter.\n",
    "\n",
    "        Args:\n",
    "            model_path (str): Path to the YOLO model file (e.g., 'yolov10s.pt').\n",
    "            conf_threshold (float): Confidence threshold for object detection.\n",
    "            device (str): Device to run the model on ('cpu' or '0' for GPU).\n",
    "            use_clahe (bool): Whether to apply CLAHE pre-processing for better contrast.\n",
    "        \"\"\"\n",
    "        self.model = YOLO(model_path)\n",
    "        self.conf_threshold = conf_threshold\n",
    "        self.device = device\n",
    "        self.use_clahe = use_clahe\n",
    "        \n",
    "        if self.use_clahe:\n",
    "            self.clahe = cv2.createCLAHE(clipLimit=2.0, tileGridSize=(8, 8))\n",
    "\n",
    "        self.vehicle_classes = {\n",
    "            2: 'car', 3: 'motorcycle', 5: 'bus', 7: 'truck'\n",
    "        }\n",
    "\n",
    "        # Tracking and movement history for centroids\n",
    "        self.track_history = defaultdict(list)\n",
    "        \n",
    "        # Real-time counts for current frame\n",
    "        self.current_vehicles_in_frame_all = {}  # All vehicles detected in current frame\n",
    "        self.current_outgoing_vehicles = set()   # IDs of vehicles flagged as outgoing in current frame\n",
    "        self.current_incoming_vehicles = set()   # IDs of vehicles flagged as incoming in current frame (new strict definition)\n",
    "\n",
    "        # To track the state of outgoing vehicles across frames (for retention)\n",
    "        self.outgoing_tracking_status = defaultdict(lambda: {'status': 'unknown', 'last_crossing_frame': -1})\n",
    "        self.outgoing_retention_frames = 30 # How many frames a vehicle remains 'outgoing' after crossing (e.g., 1 second at 30 FPS)\n",
    "\n",
    "        # Reference line for OUTGOING vehicles\n",
    "        self.outgoing_line_y = 0  # This will be set based on frame height in run()\n",
    "        \n",
    "        # Parameters for strict \"incoming\" movement (no fixed line, heuristic based on direction)\n",
    "        self.min_history_for_incoming = 15     # Number of frames to check for consistent movement before being 'incoming'\n",
    "        self.incoming_movement_threshold_y = 20 # Minimum vertical displacement (pixels) for 'incoming' movement\n",
    "        self.incoming_start_y_ratio = 0.70       # Vehicle must start its current downward trajectory above this y-ratio (e.g., top 70%)\n",
    "\n",
    "\n",
    "        # Performance metrics\n",
    "        self.start_time = time.time()\n",
    "        self.frame_count = 0\n",
    "\n",
    "    def preprocess_frame(self, frame):\n",
    "        \"\"\"Applies pre-processing steps to the frame.\"\"\"\n",
    "        if not self.use_clahe:\n",
    "            return frame\n",
    "        \n",
    "        lab = cv2.cvtColor(frame, cv2.COLOR_BGR2LAB)\n",
    "        l, a, b = cv2.split(lab)\n",
    "        l_clahe = self.clahe.apply(l)\n",
    "        lab_clahe = cv2.merge((l_clahe, a, b))\n",
    "        frame_clahe = cv2.cvtColor(lab_clahe, cv2.COLOR_LAB2BGR)\n",
    "        return frame_clahe\n",
    "\n",
    "    def process_frame(self, frame):\n",
    "        \"\"\"\n",
    "        Processes a single frame for vehicle detection, tracking, and real-time counts.\n",
    "        \"\"\"\n",
    "        self.frame_count += 1\n",
    "        \n",
    "        preprocessed_frame = self.preprocess_frame(frame)\n",
    "        \n",
    "        results = self.model.track(\n",
    "            preprocessed_frame,\n",
    "            classes=list(self.vehicle_classes.keys()),\n",
    "            conf=self.conf_threshold,\n",
    "            device=self.device,\n",
    "            persist=True,\n",
    "            tracker=\"bytetrack.yaml\",\n",
    "            verbose=False\n",
    "        )\n",
    "        \n",
    "        # Reset real-time counts for this frame\n",
    "        self.current_vehicles_in_frame_all.clear()\n",
    "        self.current_incoming_vehicles.clear() # Clear incoming set for current frame\n",
    "        self.current_outgoing_vehicles = set() # Re-evaluate current_outgoing_vehicles based on retention\n",
    "\n",
    "        frame_height = frame.shape[0]\n",
    "        \n",
    "        # Set outgoing line if not already set (e.g., first frame)\n",
    "        if self.outgoing_line_y == 0:\n",
    "            self.outgoing_line_y = int(frame_height * 0.4) # Adjust this value (0.4 = 40% from top)\n",
    "\n",
    "        current_active_track_ids = set()\n",
    "\n",
    "        if results[0].boxes.id is not None:\n",
    "            boxes = results[0].boxes.xyxy.cpu().numpy()\n",
    "            track_ids = results[0].boxes.id.cpu().numpy().astype(int)\n",
    "            classes = results[0].boxes.cls.cpu().numpy().astype(int)\n",
    "            \n",
    "            for box, track_id, cls in zip(boxes, track_ids, classes):\n",
    "                class_name = self.vehicle_classes.get(cls, 'unknown')\n",
    "                self.current_vehicles_in_frame_all[track_id] = class_name\n",
    "                current_active_track_ids.add(track_id)\n",
    "\n",
    "                cx, cy = int((box[0] + box[2]) / 2), int((box[1] + box[3]) / 2)\n",
    "                self.track_history[track_id].append((cx, cy))\n",
    "\n",
    "                # Keep a limited history for trajectory for general visualization and movement analysis\n",
    "                if len(self.track_history[track_id]) > max(self.min_history_for_incoming, 30): \n",
    "                    self.track_history[track_id].pop(0)\n",
    "\n",
    "                # --- Real-time Outgoing Vehicle Logic (with Reference Line) ---\n",
    "                if len(self.track_history[track_id]) >= 2:\n",
    "                    last_y = self.track_history[track_id][-1][1]\n",
    "                    prev_y = self.track_history[track_id][-2][1]\n",
    "\n",
    "                    # Check for crossing from below to above the line (upward movement)\n",
    "                    if prev_y >= self.outgoing_line_y and last_y < self.outgoing_line_y and last_y < prev_y:\n",
    "                        self.outgoing_tracking_status[track_id]['status'] = 'crossed_up'\n",
    "                        self.outgoing_tracking_status[track_id]['last_crossing_frame'] = self.frame_count\n",
    "                    # If it's currently below the line, reset status if it was 'crossed_up'\n",
    "                    elif last_y > self.outgoing_line_y and self.outgoing_tracking_status[track_id]['status'] == 'crossed_up':\n",
    "                        self.outgoing_tracking_status[track_id]['status'] = 'below_line'\n",
    "                    elif last_y > self.outgoing_line_y:\n",
    "                         self.outgoing_tracking_status[track_id]['status'] = 'below_line' # Explicitly mark below\n",
    "\n",
    "                # --- Real-time Incoming Vehicle Logic (Strict Heuristic - No Line) ---\n",
    "                if len(self.track_history[track_id]) >= self.min_history_for_incoming:\n",
    "                    y_positions = [pt[1] for pt in self.track_history[track_id][-self.min_history_for_incoming:]]\n",
    "                    dy = y_positions[-1] - y_positions[0] # Positive if moving down\n",
    "                    initial_y_in_history = y_positions[0]\n",
    "\n",
    "                    # Condition for \"incoming\": significant downward movement AND started from upper portion of frame\n",
    "                    if (dy > self.incoming_movement_threshold_y and \n",
    "                        initial_y_in_history < (frame_height * self.incoming_start_y_ratio)):\n",
    "                        \n",
    "                        self.current_incoming_vehicles.add(track_id)\n",
    "                \n",
    "        # Populate current_outgoing_vehicles based on 'outgoing_tracking_status' and retention\n",
    "        for track_id in current_active_track_ids: \n",
    "            status_info = self.outgoing_tracking_status[track_id]\n",
    "            if status_info['status'] == 'crossed_up' and \\\n",
    "               (self.frame_count - status_info['last_crossing_frame']) < self.outgoing_retention_frames:\n",
    "                self.current_outgoing_vehicles.add(track_id)\n",
    "\n",
    "        # Clean up history and status for lost tracks (no longer in current_active_track_ids)\n",
    "        keys_to_delete_history = [tid for tid in self.track_history if tid not in current_active_track_ids]\n",
    "        for tid in keys_to_delete_history:\n",
    "            del self.track_history[tid]\n",
    "            if tid in self.outgoing_tracking_status:\n",
    "                del self.outgoing_tracking_status[tid]\n",
    "\n",
    "        # Draw annotations on the ORIGINAL frame\n",
    "        annotated_frame = self.draw_annotations(frame, results)\n",
    "        return annotated_frame\n",
    "\n",
    "    def draw_annotations(self, frame, results):\n",
    "        \"\"\"Draws bounding boxes, tracking IDs, trajectories, and statistics.\"\"\"\n",
    "        # Draw the outgoing reference line first\n",
    "        cv2.line(frame, (0, self.outgoing_line_y), (frame.shape[1], self.outgoing_line_y), (0, 255, 255), 2) # Yellow line\n",
    "        cv2.putText(frame, \"Outgoing Line\", (10, self.outgoing_line_y - 10), cv2.FONT_HERSHEY_SIMPLEX, 0.6, (0, 255, 255), 2)\n",
    "\n",
    "        if results[0].boxes.id is not None:\n",
    "            boxes = results[0].boxes.xyxy.cpu().numpy()\n",
    "            track_ids = results[0].boxes.id.cpu().numpy().astype(int)\n",
    "            classes = results[0].boxes.cls.cpu().numpy().astype(int)\n",
    "            \n",
    "            for box, track_id, cls in zip(boxes, track_ids, classes):\n",
    "                x1, y1, x2, y2 = map(int, box)\n",
    "                class_name = self.vehicle_classes.get(cls, 'unknown')\n",
    "                \n",
    "                color = (0, 255, 0) # Default green\n",
    "\n",
    "                if track_id in self.current_outgoing_vehicles:\n",
    "                    color = (0, 0, 255) # Red for vehicles currently identified as outgoing\n",
    "                elif track_id in self.current_incoming_vehicles:\n",
    "                    color = (255, 0, 0) # Blue for vehicles currently identified as incoming (strict)\n",
    "                \n",
    "                cv2.rectangle(frame, (x1, y1), (x2, y2), color, 2)\n",
    "                label = f'ID:{track_id} {class_name}'\n",
    "                \n",
    "                label_size, _ = cv2.getTextSize(label, cv2.FONT_HERSHEY_SIMPLEX, 0.5, 2)\n",
    "                cv2.rectangle(frame, (x1, y1 - label_size[1] - 5), (x1 + label_size[0], y1), color, -1)\n",
    "                cv2.putText(frame, label, (x1, y1 - 5), cv2.FONT_HERSHEY_SIMPLEX, 0.5, (0, 0, 0), 2)\n",
    "\n",
    "                points = self.track_history.get(track_id, [])\n",
    "                if len(points) > 1:\n",
    "                    cv2.polylines(frame, [np.array(points, dtype=np.int32)], isClosed=False, color=color, thickness=2)\n",
    "\n",
    "        self.draw_statistics(frame)\n",
    "        return frame\n",
    "\n",
    "    def draw_statistics(self, frame):\n",
    "        \"\"\"Draws the statistics panel.\"\"\"\n",
    "        panel_x, panel_y, panel_w, panel_h = 10, 10, 350, 150 # Adjust panel size\n",
    "        overlay = frame.copy()\n",
    "        cv2.rectangle(overlay, (panel_x, panel_y), (panel_x + panel_w, panel_y + panel_h), (0, 0, 0), -1)\n",
    "        cv2.addWeighted(overlay, 0.6, frame, 0.4, 0, frame)\n",
    "\n",
    "        y = panel_y + 25\n",
    "        lh = 20\n",
    "        \n",
    "        # 1. Total vehicles detected in camera frame (real-time)\n",
    "        total_current_in_frame = len(self.current_vehicles_in_frame_all)\n",
    "        \n",
    "        # 2. Outgoing vehicles (real-time)\n",
    "        realtime_outgoing_count = len(self.current_outgoing_vehicles)\n",
    "\n",
    "        # 3. Real-time Incoming (Strict Heuristic) - this is your desired specific count\n",
    "        realtime_incoming_count = len(self.current_incoming_vehicles)\n",
    "        \n",
    "        cv2.putText(frame, f\"Real-time Incoming: {realtime_incoming_count}\", (panel_x + 10, y), cv2.FONT_HERSHEY_SIMPLEX, 0.6, (0, 255, 255), 2)\n",
    "        y += lh + 5\n",
    "        cv2.putText(frame, f\"Total in Frame: {total_current_in_frame}\", (panel_x + 10, y), cv2.FONT_HERSHEY_SIMPLEX, 0.6, (0, 255, 255), 2)\n",
    "        y += lh + 5\n",
    "        cv2.putText(frame, f\"Real-time Outgoing: {realtime_outgoing_count}\", (panel_x + 10, y), cv2.FONT_HERSHEY_SIMPLEX, 0.6, (0, 255, 255), 2)\n",
    "        y += lh + 10\n",
    "\n",
    "        elapsed_time = time.time() - self.start_time\n",
    "        fps = self.frame_count / elapsed_time if elapsed_time > 0 else 0\n",
    "        cv2.putText(frame, f\"FPS: {fps:.2f}\", (panel_x + 10, y + 5), cv2.FONT_HERSHEY_SIMPLEX, 0.6, (0, 255, 0), 2)\n",
    "\n",
    "    def run(self, source_path):\n",
    "        \"\"\"Runs the vehicle counting process on a video file or camera source.\"\"\"\n",
    "        cap = cv2.VideoCapture(source_path)\n",
    "        if not cap.isOpened():\n",
    "            print(f\"Error: Could not open video source: {source_path}\")\n",
    "            return\n",
    "\n",
    "        display_width, display_height = 1280, 720\n",
    "        print(\"Real-time vehicle counter started. Press 'q' to quit.\")\n",
    "\n",
    "        while True:\n",
    "            ret, frame = cap.read()\n",
    "            if not ret:\n",
    "                print(\"End of video stream.\")\n",
    "                break\n",
    "\n",
    "            frame = cv2.resize(frame, (display_width, display_height))\n",
    "            processed_frame = self.process_frame(frame)\n",
    "            cv2.imshow(\"Real-time Vehicle Traffic Analysis\", processed_frame)\n",
    "\n",
    "            if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "                break\n",
    "\n",
    "        cap.release()\n",
    "        cv2.destroyAllWindows()\n",
    "        print(\"\\nReal-time counting session ended.\")\n",
    "\n",
    "\n",
    "def main():\n",
    "    model = 'yolov10n.pt'  \n",
    "    device_to_use = 'cpu'  \n",
    "    use_image_enhancement = True\n",
    "    video_source = \"adi.mp4\" \n",
    "\n",
    "    counter = VehicleCounter(\n",
    "        model_path=model,  \n",
    "        device=device_to_use,  \n",
    "        conf_threshold=0.3,\n",
    "        use_clahe=use_image_enhancement\n",
    "    )\n",
    "    counter.run(source_path=video_source)\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2bc70b8-cd96-48a5-98dd-6115a9e01d98",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (ultralytics)",
   "language": "python",
   "name": "ultralytics"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
